# 逆矩阵、秩与列空间、零空间

本节有许多概念，要介绍它们，需要从”线性方程组“说起。

方程组就是含有未知数的等式组，方程组可以很复杂，但线性方程组的形式相对简单。线性方程组有几个特点：未知数的系数都是常数、各项间只有加减、未知数都是一次方。

下面是线性方程组的一个例子：
$$
2x+5y+3z=-3\\
4x+0y+8z=0\\
1x+3y+0z=2
$$
## 逆矩阵

线性方程组可以通过矩阵求解。我们将其整理成向量与矩阵相乘的形式：
$$
\begin{bmatrix}2&5&3\\4&0&8\\1&3&0\end{bmatrix}
\begin{bmatrix}x\\y\\z\end{bmatrix}=
\begin{bmatrix}-3\\0\\2\end{bmatrix}
$$
这就回到了我们熟悉的线性变换，等式可以表示为：
$$
A\vec{x}=\vec{v}
$$
其中 $A$ 表示线性变换矩阵，$\vec{x}$ 表示方程组的解。

<img class="img-shadow" src="https://raw.githubusercontent.com/yamsfeer/pic-bed/master/e6c9d24egy1h31w6flcpmg20k00b91kx.gif" alt="Kapture 2022-06-08 at 13.47.54" style="zoom:75%;" />

也就是说，我们在求一个向量 $x$，它在线性变换后等于向量 $v$。

假设 $A$ 表示顺时针旋转 90 度，$x$ 变换后得到 $v$，则 $v$ 可以逆时针旋转 90 度得到 $x$，这称为 $A$ 的逆变换 $A^{-1}$ *(Inverse Transformation)*。

不难看出，$A$ 和 $A^{-1}$ 复合变换相当于什么都不做，即它们相乘得到单位矩阵 $I$。
$$
AA^{-1}=I
$$
<img class="img-shadow" src="https://raw.githubusercontent.com/yamsfeer/pic-bed/master/e6c9d24egy1h31w6ppdsag20k00b9e21.gif" alt="Kapture 2022-06-08 at 13.53.04" style="zoom:75%;" />

要想计算向量 $x$，只需要两边乘以 $A^{-1}$，可以类比除法。
$$
A^{-1}A\vec{x}=A^{-1}\vec{v} \quad\longrightarrow\quad  \vec{x}=A^{-1}\vec{v}
$$
*（具体怎么求一个矩阵的逆矩阵不是本节的内容）*

### 解是否存在

这里还有一个问题，有没有可能一个变换矩阵不存在逆矩阵？

* 只要变换不将空间降维，即 $det(A) \ne 0$，则存在逆变换且线性方程组有唯一解。

* 如果 $det(A)=0$，空间被降维，此时**没有逆变换**，因为你无法将直线“拓展”成平面甚至立方体。

<img class="img-shadow" src="https://raw.githubusercontent.com/yamsfeer/pic-bed/master/e6c9d24egy1h326bkljagg20k00b9e81.gif" alt="Kapture 2022-06-08 at 13.56.16" style="zoom:75%;" />

当然，也不是说行列式为 0 就一定不存在解，比如 $\vec{v}$ 恰好落在直线上时就有解。

<img class="img-shadow" src="https://raw.githubusercontent.com/yamsfeer/pic-bed/master/e6c9d24egy1h326bm6eycg20k00b915z.gif" alt="Kapture 2022-06-08 at 13.58.26" style="zoom:75%;" />

要判断 $\vec{v}$ 是否恰好落在直线上（是否存在解），需要用到矩阵的列空间。

在这之前先介绍一个新的概念：矩阵的秩。

## 矩阵的秩与列空间

秩 *( rank )* 表示变换后空间的维数。

对于一个 2 x 2 的矩阵 $A$，它的秩最大为 2。很明显，$A$ 的秩还可能等于 1 ( 压缩成直线 ) 或 0 ( 压缩成原点 )。

如果变换后空间维数不变，称为满秩 *( full rank )* 。

<img class="img-shadow" src="https://raw.githubusercontent.com/yamsfeer/pic-bed/master/e6c9d24egy1h326h88nrog20k00b94bw.gif" alt="Kapture 2022-06-08 at 13.58.26" style="zoom:75%;" />

不管是直线、平面还是 3 维空间，所有可能的变换结果的集合，称为矩阵的“列空间” *( column space )* 。

矩阵的列表示的是变换后的基向量，而基向量张成的空间就是所有可能的变换结果，因此称为列空间。

准确地说，秩就是列空间的维数。

<img class="img-shadow" src="https://raw.githubusercontent.com/yamsfeer/pic-bed/master/e6c9d24egy1h3270jyrnxg20k00b9x3z.gif" alt="Kapture 2022-06-08 at 14.02.32" style="zoom:75%;" />

这里可以小结一下，一个方程组 $A\vec{x}=\vec{v}$ 要想有解，$\vec{v}$ 必须在 $A$ 的列空间中，不然 $\vec{x}$ 不可能通过 $A$ 变换得到 $\vec{v}$，也就不可能有解。

## 矩阵的零空间

如果 $det(A)=0$，则必然有向量会在变换后成为零向量。

比如一个平面在 $A$ 变换后压缩到一条直线，则平面中的一条直线会被压缩成零点；一个 3 维空间被压缩成直线，则有一个平面的向量被压缩成零点。

变换后落在原点的向量的集合，成为矩阵的“零空间” *( null space )* 或“核” *( kernel )* 。换句话说，零空间的向量会在变换后成为零向量。

<img class="img-shadow" src="https://raw.githubusercontent.com/yamsfeer/pic-bed/master/e6c9d24egy1h327brit2lg20k00b91l0.gif" alt="Kapture 2022-06-08 at 14.02.32" style="zoom:75%;" />

对于方程组 $A\vec{x}=\begin{bmatrix}0\\0\end{bmatrix}$ 来说，$A$ 的零空间里的向量正是方程组的解。

## 总结

<img class="img-shadow" src="https://raw.githubusercontent.com/yamsfeer/pic-bed/master/e6c9d24egy1h327fo52bng20k00b91kx.gif" alt="Kapture 2022-06-09 at 12.03.05" style="zoom:75%;" />

对于一个线性方程组，它可以写成 $A\vec{x}=\vec{v}$ 的形式。

* 如果 $det(A) \ne 0$，$A$ 存在逆矩阵，则通过逆矩阵求方程组的解：$\vec{x} = A^{-1}\vec{v}$。
* 如果 $det(A) = 0$
  * $A$ 的列空间可以判断方程组的解是否存在，如果存在解，则 $\vec{v}$ 一定在 $A$ 的列空间中。
  * $A$ 的零空间可以帮助我们理解所有可能的解的集合是什么样的。
